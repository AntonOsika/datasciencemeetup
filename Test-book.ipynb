{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as its\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.preprocessing.sequence as pps\n",
    "import keras.preprocessing.text as ppt\n",
    "import keras.layers.wrappers as wrappers\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "histories = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- cmp performance with one hot data\n",
    "- generate text (-> simplify model?)\n",
    "- use word dataset\n",
    "- generate text with word dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d\\xc3\\xa5': 2, 'haha': 4, 'hehe': 1, 'hej': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = ppt.Tokenizer(1) \n",
    "\n",
    "tt.fit_on_texts([\"hej hej hej då då då\", \"haha hehe hehe hehe\"])\n",
    "tt.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "chars_to_keep = string.ascii_lowercase + ' ' + ',' + '.' + '?' +'0' + '1'#+ '!' + '(' + ')' + '/' + ':' + ';' + '\\\"' + '0' + '1' + '2'\n",
    "ord_dict = dict(zip(chars_to_keep, 1 + np.arange(len(chars_to_keep), dtype=np.int8)))\n",
    "char_dict = dict(zip(np.arange(len(chars_to_keep), dtype=np.int8), chars_to_keep))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def string_to_array(s):\n",
    "    def maybe_char(c):\n",
    "        if c in chars_to_keep:\n",
    "            return c\n",
    "        if c == '-' or c == '_':\n",
    "            return ' '\n",
    "        if c == '!':\n",
    "            return '.'\n",
    "        if c == ':':\n",
    "            return ','\n",
    "        if c in string.digits:\n",
    "            return '1'\n",
    "        return \"\"\n",
    "    return np.array([ord_dict[c] for c in \"\".join(map(maybe_char, s.lower()))], np.int8)\n",
    "\n",
    "\n",
    "\n",
    "def get_data(folder='/Users/anton/Downloads/aclimdb', files_to_use=1.0, max_len=80, train_data=True):\n",
    "    # Takes the first files_to_use files from both folders and pads to max_len\n",
    "    \n",
    "    if train_data:\n",
    "        folder += '/train'\n",
    "    else:\n",
    "        folder += '/test'\n",
    "        \n",
    "    X = []\n",
    "    X_lengths = []\n",
    "    lengths = []\n",
    "    sub_folders = ['pos', 'neg']\n",
    "    for sub_folder in sub_folders:\n",
    "        path = folder + '/' + sub_folder + \"/\"\n",
    "        files = os.listdir(path)\n",
    "        files = files[:int(len(files)*files_to_use)]\n",
    "        lengths.append(len(files))\n",
    "\n",
    "        for fn in files:\n",
    "            #import IPython.core.debugger as ipdb;ipdb.set_trace()\n",
    "\n",
    "            try:\n",
    "                f = file(path + fn, 'r')\n",
    "                ss = f.read()\n",
    "            except Exception as e:\n",
    "                print \"Could not open file %s, error: %s %s %s\"% (fn, type(e), e.__str__(), sys.exc_info()[0])\n",
    "            \n",
    "            X.append(string_to_array(ss))\n",
    "            X_lengths.append(len(ss))\n",
    "\n",
    "\n",
    "    X = keras.preprocessing.sequence.pad_sequences(X, max_len)\n",
    "    y = np.concatenate((np.ones(lengths[0]), np.zeros(lengths[1])))\n",
    "    \n",
    "    np.random.seed(7)\n",
    "    np.random.shuffle(X)\n",
    "    \n",
    "    np.random.seed(7)\n",
    "    np.random.shuffle(y)\n",
    "    \n",
    "    return X, y.reshape((y.size,-1)), X_lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_m1():\n",
    "    n_units_1 = 50\n",
    "\n",
    "    n_units_2 = 128\n",
    "\n",
    "    n_characters = len(chars_to_keep)\n",
    "\n",
    "    dropout_p = 0.2\n",
    "\n",
    "#    dropout_p = 0.0\n",
    "\n",
    "\n",
    "    m = keras.models.Sequential()\n",
    "\n",
    "    one_hot_embedding = np.concatenate((np.zeros((n_characters, 1)), np.eye(n_characters)), axis=1).T\n",
    "\n",
    "\n",
    "    m.add(keras.layers.Embedding(n_characters + 1, n_characters, mask_zero=True, weights=[one_hot_embedding], trainable=False))\n",
    "\n",
    "    m.add( wrappers.Bidirectional( keras.layers.LSTM( n_units_1, dropout=dropout_p/2, return_sequences=True ) ))\n",
    "    #m.add( keras.layers.LSTM( n_units_2, dropout=dropout_p, return_sequences=True ) )\n",
    "    m.add( keras.layers.LSTM( n_units_2, dropout=dropout_p ) )\n",
    "\n",
    "    m.add( keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    m.compile('adam', 'binary_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, lengths = get_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 800)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = sentiment_m1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/15\n",
      "21250/21250 [==============================] - 221s - loss: 0.4666 - acc: 0.7671 - val_loss: 0.6770 - val_acc: 0.6640\n",
      "Epoch 2/15\n",
      "21250/21250 [==============================] - 219s - loss: 0.4575 - acc: 0.7760 - val_loss: 0.6981 - val_acc: 0.6613\n",
      "Epoch 3/15\n",
      "21250/21250 [==============================] - 221s - loss: 0.4555 - acc: 0.7768 - val_loss: 0.6615 - val_acc: 0.6688\n",
      "Epoch 4/15\n",
      "21250/21250 [==============================] - 220s - loss: 0.4497 - acc: 0.7779 - val_loss: 0.6731 - val_acc: 0.6603\n",
      "Epoch 5/15\n",
      "21250/21250 [==============================] - 219s - loss: 0.4390 - acc: 0.7854 - val_loss: 0.6870 - val_acc: 0.6688\n",
      "Epoch 6/15\n",
      "21250/21250 [==============================] - 220s - loss: 0.4372 - acc: 0.7853 - val_loss: 0.6949 - val_acc: 0.6605\n",
      "Epoch 7/15\n",
      "21250/21250 [==============================] - 220s - loss: 0.4322 - acc: 0.7907 - val_loss: 0.7039 - val_acc: 0.6661\n",
      "Epoch 8/15\n",
      "21250/21250 [==============================] - 219s - loss: 0.4227 - acc: 0.7956 - val_loss: 0.6855 - val_acc: 0.6645\n",
      "Epoch 9/15\n",
      "21250/21250 [==============================] - 219s - loss: 0.4174 - acc: 0.7993 - val_loss: 0.6987 - val_acc: 0.6744\n",
      "Epoch 10/15\n",
      "21250/21250 [==============================] - 220s - loss: 0.4129 - acc: 0.8008 - val_loss: 0.6729 - val_acc: 0.6725\n",
      "Epoch 11/15\n",
      "21250/21250 [==============================] - 220s - loss: 0.4049 - acc: 0.8066 - val_loss: 0.7551 - val_acc: 0.6669\n",
      "Epoch 12/15\n",
      "21250/21250 [==============================] - 220s - loss: 0.4002 - acc: 0.8082 - val_loss: 0.7086 - val_acc: 0.6603\n",
      "Epoch 13/15\n",
      "21250/21250 [==============================] - 220s - loss: 0.4023 - acc: 0.8095 - val_loss: 0.6914 - val_acc: 0.6680\n",
      "Epoch 14/15\n",
      "21250/21250 [==============================] - 220s - loss: 0.3944 - acc: 0.8150 - val_loss: 0.6978 - val_acc: 0.6747\n",
      "Epoch 15/15\n",
      "21250/21250 [==============================] - 221s - loss: 0.3892 - acc: 0.8166 - val_loss: 0.7356 - val_acc: 0.6653\n",
      "3307.55[s] elapsed\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "batch_size = 64\n",
    "n_epochs = 15\n",
    "\n",
    "history = m.fit(X, y, epochs=n_epochs, validation_split=0.15, shuffle=False, batch_size=batch_size)\n",
    "history_list.append(history)\n",
    "print( \"%g[s] elapsed\" % (time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  5, 10], dtype=int8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113a9c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths, bins=100, range=(0,4000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text_m1( n_characters ):\n",
    "    \n",
    "    n_units = 512\n",
    "\n",
    "    m = keras.models.Sequential()\n",
    "\n",
    "    m.add( keras.layers.Embedding(n_characters + 2, n_characters, mask_zero=True) )\n",
    "    m.add( keras.layers.LSTM(n_units, return_sequences=True))\n",
    "    m.add( keras.layers.Dropout(0.5))\n",
    "    m.add( keras.layers.LSTM(n_units, return_sequences=True))\n",
    "    m.add( keras.layers.Dropout(0.5))\n",
    "    m.add( keras.layers.Dense(n_characters + 1, activation='softmax') )\n",
    "\n",
    "    m.compile('adam', loss='sparse_categorical_crossentropy' )\n",
    "\n",
    "\n",
    "    return m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_model = generate_text_m1(len(chars_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "22500/22500 [==============================] - 1147s - loss: 2.7249 - val_loss: 2.2298\n",
      "Epoch 2/10\n",
      "22500/22500 [==============================] - 1109s - loss: 2.0629 - val_loss: 1.7819\n",
      "Epoch 3/10\n",
      "22500/22500 [==============================] - 1056s - loss: 1.7601 - val_loss: 1.5697\n",
      "Epoch 4/10\n",
      "22500/22500 [==============================] - 1023s - loss: 1.6121 - val_loss: 1.4639\n",
      "Epoch 5/10\n",
      "22500/22500 [==============================] - 1117s - loss: 1.5256 - val_loss: 1.4024\n",
      "Epoch 6/10\n",
      "22500/22500 [==============================] - 1161s - loss: 1.4691 - val_loss: 1.3622\n",
      "Epoch 7/10\n",
      "22500/22500 [==============================] - 1025s - loss: 1.4304 - val_loss: 1.3375\n",
      "Epoch 8/10\n",
      "22500/22500 [==============================] - 1075s - loss: 1.4006 - val_loss: 1.3134\n",
      "Epoch 9/10\n",
      "22500/22500 [==============================] - 1087s - loss: 1.3767 - val_loss: 1.2981\n",
      "Epoch 10/10\n",
      "22500/22500 [==============================] - 1138s - loss: 1.3570 - val_loss: 1.2860\n"
     ]
    }
   ],
   "source": [
    "histories['generate_text_m1'].append(gen_model.fit(X[:, :-1], X[:, 1:, np.newaxis], validation_split=0.10, shuffle=False, batch_size=batch_size, epochs=10 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 79, 80)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.predict(X[:1, :-1])[:, :, X[0, 1:]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = histories['generate_text_m1'].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_char(m, text=\"\"):\n",
    "     return np.random.choice( list(chars_to_keep)+['_'], p=m.predict(string_to_array('hej')[np.newaxis, :])[0, -1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(m, N):\n",
    "    text = \"\"\n",
    "    for i in range(N):\n",
    "        text += generate_char(m, text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xpnfvqqppq'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(mm, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  5, 10]], dtype=int8)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_array('hej')[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "range() integer end argument expected, got str.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-0fcc22c47dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-120-4ee04da52168>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(m, N)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgenerate_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: range() integer end argument expected, got str."
     ]
    }
   ],
   "source": [
    "generate_text(mm, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model 2:\n",
    "\n",
    "n_units_1 = 50\n",
    "\n",
    "n_units_2 = 128\n",
    "\n",
    "#n_characters = 28\n",
    "n_characters = len(chars_to_keep)\n",
    "\n",
    "dropout_p = 0.2\n",
    "\n",
    "dropout_p = 0.0\n",
    "\n",
    "\n",
    "m2 = keras.models.Sequential()\n",
    "\n",
    "one_hot_embedding = np.concatenate((np.zeros((n_characters, 1)), np.eye(n_characters)), axis=1).T\n",
    "\n",
    "m2.add(keras.layers.Embedding(n_characters + 1, n_characters, mask_zero=True, weights=[one_hot_embedding]))\n",
    "\n",
    "\n",
    "m2.add( keras.layers.LSTM( n_units_2, dropout=dropout_p/2.0 ) )\n",
    "\n",
    "\n",
    "m2.add( keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "m2.compile('adam', 'binary_crossentropy', metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21250 samples, validate on 3750 samples\n",
      "Epoch 1/15\n",
      "1155s - loss: 0.6905 - acc: 0.5287 - val_loss: 0.6899 - val_acc: 0.5213\n",
      "Epoch 2/15\n",
      "1138s - loss: 0.6922 - acc: 0.5337 - val_loss: 0.6904 - val_acc: 0.5165\n",
      "Epoch 3/15\n",
      "1141s - loss: 0.6859 - acc: 0.5437 - val_loss: 0.6884 - val_acc: 0.5325\n",
      "Epoch 4/15\n",
      "1141s - loss: 0.6815 - acc: 0.5569 - val_loss: 0.6881 - val_acc: 0.5283\n",
      "Epoch 5/15\n",
      "1139s - loss: 0.6796 - acc: 0.5603 - val_loss: 0.6857 - val_acc: 0.5456\n",
      "Epoch 6/15\n",
      "1136s - loss: 0.6857 - acc: 0.5435 - val_loss: 0.6949 - val_acc: 0.5176\n",
      "Epoch 7/15\n",
      "1142s - loss: 0.6851 - acc: 0.5469 - val_loss: 0.6917 - val_acc: 0.5285\n",
      "Epoch 8/15\n",
      "1142s - loss: 0.6801 - acc: 0.5584 - val_loss: 0.6845 - val_acc: 0.5349\n",
      "Epoch 9/15\n",
      "1139s - loss: 0.6760 - acc: 0.5699 - val_loss: 0.6749 - val_acc: 0.5653\n",
      "Epoch 10/15\n",
      "1141s - loss: 0.6739 - acc: 0.5713 - val_loss: 0.6814 - val_acc: 0.5403\n",
      "Epoch 11/15\n",
      "1144s - loss: 0.6793 - acc: 0.5617 - val_loss: 0.6937 - val_acc: 0.5147\n",
      "Epoch 12/15\n",
      "1141s - loss: 0.6934 - acc: 0.5151 - val_loss: 0.6982 - val_acc: 0.4944\n",
      "Epoch 13/15\n",
      "1140s - loss: 0.6911 - acc: 0.5214 - val_loss: 0.6955 - val_acc: 0.5099\n",
      "Epoch 14/15\n",
      "1143s - loss: 0.6882 - acc: 0.5296 - val_loss: 0.6901 - val_acc: 0.5336\n",
      "Epoch 15/15\n",
      "1152s - loss: 0.6855 - acc: 0.5422 - val_loss: 0.6876 - val_acc: 0.5363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "n_epochs = 15\n",
    "\n",
    "history = m2.fit(X, y, epochs=n_epochs, validation_split=0.15, shuffle=False, verbose=2, batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "charss = np.array([-128, -127, -126, -125, -124, -123, -120, -119, -118, -115, -114,\n",
    "       -111, -109, -107, -106, -105, -104, -103, -102, -100,  -99,  -98,\n",
    "        -97,  -96,  -95,  -94,  -93,  -92,  -91,  -90,  -89,  -88,  -87,\n",
    "        -86,  -85,  -84,  -83,  -82,  -81,  -80,  -79,  -78,  -77,  -76,\n",
    "        -74,  -73,  -72,  -71,  -70,  -69,  -68,  -67,  -66,  -65,  -62,\n",
    "        -61,  -59,  -30,  -17,    8,    9,   16,   32,   33,   34,   35,\n",
    "         36,   37,   38,   39,   40,   41,   42,   43,   44,   45,   46,\n",
    "         47,   48,   49,   50,   51,   52,   53,   54,   55,   56,   57,\n",
    "         58,   59,   60,   61,   62,   63,   64,   65,   66,   67,   68,\n",
    "         69,   70,   71,   72,   73,   74,   75,   76,   77,   78,   79,\n",
    "         80,   81,   82,   83,   84,   85,   86,   87,   88,   89,   90,\n",
    "         91,   92,   93,   94,   95,   96,   97,   98,   99,  100,  101,\n",
    "        102,  103,  104,  105,  106,  107,  108,  109,  110,  111,  112,\n",
    "        113,  114,  115,  116,  117,  118,  119,  120,  121,  122,  123,\n",
    "        124,  125,  126])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = charss %256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x80',\n",
       " '\\x81',\n",
       " '\\x82',\n",
       " '\\x83',\n",
       " '\\x84',\n",
       " '\\x85',\n",
       " '\\x88',\n",
       " '\\x89',\n",
       " '\\x8a',\n",
       " '\\x8d',\n",
       " '\\x8e',\n",
       " '\\x91',\n",
       " '\\x93',\n",
       " '\\x95',\n",
       " '\\x96',\n",
       " '\\x97',\n",
       " '\\x98',\n",
       " '\\x99',\n",
       " '\\x9a',\n",
       " '\\x9c',\n",
       " '\\x9d',\n",
       " '\\x9e',\n",
       " '\\x9f',\n",
       " '\\xa0',\n",
       " '\\xa1',\n",
       " '\\xa2',\n",
       " '\\xa3',\n",
       " '\\xa4',\n",
       " '\\xa5',\n",
       " '\\xa6',\n",
       " '\\xa7',\n",
       " '\\xa8',\n",
       " '\\xa9',\n",
       " '\\xaa',\n",
       " '\\xab',\n",
       " '\\xac',\n",
       " '\\xad',\n",
       " '\\xae',\n",
       " '\\xaf',\n",
       " '\\xb0',\n",
       " '\\xb1',\n",
       " '\\xb2',\n",
       " '\\xb3',\n",
       " '\\xb4',\n",
       " '\\xb6',\n",
       " '\\xb7',\n",
       " '\\xb8',\n",
       " '\\xb9',\n",
       " '\\xba',\n",
       " '\\xbb',\n",
       " '\\xbc',\n",
       " '\\xbd',\n",
       " '\\xbe',\n",
       " '\\xbf',\n",
       " '\\xc2',\n",
       " '\\xc3',\n",
       " '\\xc5',\n",
       " '\\xe2',\n",
       " '\\xef',\n",
       " '\\x08',\n",
       " '\\t',\n",
       " '\\x10',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(chr, cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
