{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as its\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.preprocessing.sequence as pps\n",
    "import keras.layers.wrappers as wrappers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# We get rid of most possible characters:\n",
    "chars_to_keep = string.ascii_lowercase  + string.digits + ' ' + ',' + '.' + '?' + '!' + '(' + ')' + '/' + ':' + '-' + '\\\"' + '\\''\n",
    "\n",
    "char_to_idx = { c : i for i, c in enumerate(chars_to_keep)}\n",
    "idx_to_char = {i : c for i, c in enumerate(chars_to_keep)}\n",
    "\n",
    "\n",
    "\n",
    "def string_to_array(s):\n",
    "    # map maybe_char() to input to remove uncomon characters:\n",
    "    def maybe_char(c):\n",
    "        if c in chars_to_keep:\n",
    "            return c\n",
    "        return \"\"\n",
    "    # Return a numpy array:\n",
    "    return np.array([char_to_idx[c] for c in \"\".join(map(maybe_char, s.lower()))], np.int8)\n",
    "\n",
    "\n",
    "\n",
    "def get_data(folder='aclImdb', files_to_use=0.1, train_data=True):\n",
    "    # Takes the first files_to_use files from both folders (max 25000 of each) and pads with zeros to max_len\n",
    "    \n",
    "    if train_data:\n",
    "        folder += '/train'\n",
    "    else:\n",
    "        folder += '/test'\n",
    "        \n",
    "    X = []\n",
    "    sub_folders = ['pos', 'neg']\n",
    "    for sub_folder in sub_folders:\n",
    "        path = folder + '/' + sub_folder + \"/\"\n",
    "        files = os.listdir(path)\n",
    "        \n",
    "        # Only take the fraction files_to_use \n",
    "        files = files[:int(len(files)*files_to_use)]\n",
    "\n",
    "        for fn in files:\n",
    "\n",
    "            try:\n",
    "                f = file(path + fn, 'r')\n",
    "                ss = f.read()\n",
    "                f.close()\n",
    "            except Exception as e:\n",
    "                print \"Could not open file %s, error: %s %s %s\"% (fn, type(e), e.__str__(), sys.exc_info()[0])\n",
    "            \n",
    "            X.append(string_to_array(ss))\n",
    "\n",
    "    corpus = np.concatenate(X)\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 10\n",
    "chunks = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, corpus.shape[0] - maxlen - 1):\n",
    "    chunks.append(corpus[i: i + maxlen])\n",
    "    next_chars.append(corpus[i + maxlen])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.zeros((len(chunks), maxlen, len(chars_to_keep)), dtype=np.bool)\n",
    "y = np.zeros((len(chunks), len(chars_to_keep)), dtype=np.bool)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    for t, char in enumerate(chunk):\n",
    "        X[i, t, char] = 1\n",
    "    y[i, next_chars[i]] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars_to_keep))))\n",
    "model.add(Dense(len(chars_to_keep), activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3152861/3152861 [==============================] - 1547s - loss: 1.5930  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11eeb6ed0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train the model, output generated text after each iteration\n",
    "model.fit(X, y,\n",
    "          batch_size=128,\n",
    "          epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my favourite kashets and the custed by plyel millicane of the point. i have been shet have as chappen that it's leaving of marties thirk i very innicences out sometice, and def so get to make she were never more of sows to the deteated by and might remember as a film of trum lost of rest were amazing to how we read this cower watch, and sucklarachnion, a cast over and away a real fre solries kids for lausye\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "start_index = random.randint(0, len(corpus) - maxlen - 1)\n",
    "\n",
    "temperature = 1.0\n",
    "\n",
    "chunk = corpus[start_index: start_index + maxlen]\n",
    "text = \"\".join(map(lambda k: idx_to_char[k], chunk))\n",
    "\n",
    "x = np.zeros((1, maxlen, len(chars_to_keep)))\n",
    "\n",
    "for t, char in enumerate(text):\n",
    "    x[0, t, char_to_idx[char]] = 1\n",
    "\n",
    "\n",
    "\n",
    "sys.stdout.write(text)\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, maxlen, len(chars_to_keep)))\n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_to_idx[char]] = 1\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = idx_to_char[next_index]\n",
    "\n",
    "    text = text[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[:3655053]\n",
    "y = y[:3655053]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10965161, 10, 48)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3655053, 48)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32895484"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
